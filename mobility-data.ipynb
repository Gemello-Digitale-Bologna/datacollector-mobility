{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6effd0c6-c127-4499-92aa-963101c4601d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import digitalhub as dh\n",
    "import os\n",
    "PROJECT_NAME = \"mobility-data\"\n",
    "project = dh.get_or_create_project(PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ba9323-b2bd-4fff-a494-193efd5f3e37",
   "metadata": {},
   "source": [
    "## Open Data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9b7ab47-2d1d-449e-bbf1-43bea0861cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_folder ='src'\n",
    "if not os.path.exists(new_folder):\n",
    "    os.makedirs(new_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1fb9814c-1e96-4d64-a057-986f8424eb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_download_road_areas = project.new_function(name=\"download-road-areas\",\n",
    "                                               kind=\"python\",\n",
    "                                               python_version=\"PYTHON3_10\",\n",
    "                                               source={\"source\": \"src/download-open-data.py\", \"handler\": \"download_road_areas\"},\n",
    "                                               requirements= [\"geopandas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "90c46404-5465-4a74-8d1d-a4c96acd6a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_road_areas = func_download_road_areas.run(action=\"job\", parameters={'bucket': 'datalake'}, local_execution=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5135621a-e01e-4c68-87fc-334dd3081ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_download_road_edges = project.new_function(name=\"download-road-edges\",\n",
    "                                               kind=\"python\",\n",
    "                                               python_version=\"PYTHON3_10\",\n",
    "                                               source={\"source\": \"src/download-open-data.py\", \"handler\": \"download_road_edges\"},\n",
    "                                               requirements= [\"geopandas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f50cd449-9866-44c5-a492-6a019de5a2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_road_edges = func_download_road_edges.run(action=\"job\", parameters={'bucket': 'datalake'}, local_execution=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2ee217d7-c86d-4acb-97c9-672a2e10e954",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_download_road_nodes = project.new_function(name=\"download-road-nodes\",\n",
    "                                               kind=\"python\",\n",
    "                                               python_version=\"PYTHON3_10\",\n",
    "                                               source={\"source\": \"src/download-open-data.py\", \"handler\": \"download_road_nodes\"},\n",
    "                                               requirements= [\"geopandas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "78ecb3d0-0598-4e46-8d8a-5b89a74b097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_road_nodes = func_download_road_nodes.run(action=\"job\", parameters={'bucket': 'datalake'}, local_execution=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9630c407-5f8f-4edd-bd78-2ea4db256bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_download_curves = project.new_function(name=\"download-curves\",\n",
    "                                               kind=\"python\",\n",
    "                                               python_version=\"PYTHON3_10\",\n",
    "                                               source={\"source\": \"src/download-open-data.py\", \"handler\": \"download_curves\"},\n",
    "                                               requirements= [\"geopandas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c9223a11-f72b-4a11-b6c2-96cb47dabfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_curves = func_download_curves.run(action=\"job\", parameters={'bucket': 'datalake'}, local_execution=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f296319d-2434-4ed4-8bfb-16cd48dfce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_download_sidewalks = project.new_function(name=\"download-sidewalks\",\n",
    "                                               kind=\"python\",\n",
    "                                               python_version=\"PYTHON3_10\",\n",
    "                                               source={\"source\": \"src/download-open-data.py\", \"handler\": \"download_sidewalks\"},\n",
    "                                               requirements= [\"geopandas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "acbfb792-bc5f-4338-849e-8ea7dd87d038",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_sidewalks = func_download_sidewalks.run(action=\"job\", parameters={'bucket': 'datalake'}, local_execution=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "295ac699-db5e-428e-9bb5-a51cea0e4c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_download_city30 = project.new_function(name=\"download-city30\",\n",
    "                                               kind=\"python\",\n",
    "                                               python_version=\"PYTHON3_10\",\n",
    "                                               source={\"source\": \"src/download-open-data.py\", \"handler\": \"download_city_30\"},\n",
    "                                               requirements= [\"geopandas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c6f61d7b-c8fb-4e9c-8601-34deb1806908",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_city30 = func_download_city30.run(action=\"job\", parameters={'bucket': 'datalake'}, local_execution=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6ed32be2-1536-439b-bab0-711d473ba0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_download_charging_stations = project.new_function(name=\"download-charging-stations\",\n",
    "                                               kind=\"python\",\n",
    "                                               python_version=\"PYTHON3_10\",\n",
    "                                               source={\"source\": \"src/download-open-data.py\", \"handler\": \"download_charging_stations\"},\n",
    "                                               requirements= [\"geopandas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1f867ffc-145c-40dd-b6bf-34dc8981a63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_charging_stations = func_download_charging_stations.run(action=\"job\", parameters={'bucket': 'datalake'}, local_execution=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c3558d2d-19fa-4da2-9c7f-2794722b5c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_download_bike_path = project.new_function(name=\"download-bike-path\",\n",
    "                                               kind=\"python\",\n",
    "                                               python_version=\"PYTHON3_10\",\n",
    "                                               source={\"source\": \"src/download-open-data.py\", \"handler\": \"download_bike_path\"},\n",
    "                                               requirements= [\"geopandas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "af9b4414-8409-4fe8-8c1a-3793aa05e203",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_bike_path = func_download_bike_path.run(action=\"job\", parameters={'bucket': 'datalake'}, local_execution=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "74bf1e38-b47c-42f2-9793-8316ad978fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_download_incidents = project.new_function(name=\"download-incidents\",\n",
    "                                               kind=\"python\",\n",
    "                                               python_version=\"PYTHON3_10\",\n",
    "                                               source={\"source\": \"src/download-open-data.py\", \"handler\": \"download_incidents\"},\n",
    "                                               requirements= [\"geopandas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2ae1fbc0-6ee7-42d7-85db-329a3cff6921",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_incidents = func_download_incidents.run(action=\"job\", parameters={'bucket': 'datalake'}, local_execution=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9254682b-53c0-4b6b-bec4-0824c3a6bdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_download_bike_parking_places = project.new_function(name=\"download-bike-parking-places\",\n",
    "                                               kind=\"python\",\n",
    "                                               python_version=\"PYTHON3_10\",\n",
    "                                               source={\"source\": \"src/download-open-data.py\", \"handler\": \"download_bike_parking_places\"},\n",
    "                                               requirements= [\"geopandas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a0fac73f-ff58-4cc1-b59c-9913390c09d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_bike_parking_places = func_download_bike_parking_places.run(action=\"job\", parameters={'bucket': 'datalake'}, local_execution=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7267f03c-e386-42f4-ba73-3522c3a301df",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_download_car_parkings = project.new_function(name=\"download-bike-parking-places\",\n",
    "                                               kind=\"python\",\n",
    "                                               python_version=\"PYTHON3_10\",\n",
    "                                               source={\"source\": \"src/download-open-data.py\", \"handler\": \"download_car_parkings\"},\n",
    "                                               requirements= [\"geopandas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a8015c2c-8d3e-4cec-926e-b9b5ef4d9d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_car_parkings = func_download_car_parkings.run(action=\"job\", parameters={'bucket': 'datalake'}, local_execution=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "21274d7f-9128-4def-95d8-6ce39161c110",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_download_bus_stops_tper = project.new_function(name=\"download-bus-stops-tper\",\n",
    "                                               kind=\"python\",\n",
    "                                               python_version=\"PYTHON3_10\",\n",
    "                                               source={\"source\": \"src/download-open-data.py\", \"handler\": \"download_bus_stops_tper\"},\n",
    "                                               requirements= [\"geopandas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0f3904b3-da9e-4a99-8708-f9fab253a406",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_bus_stops_tper = func_download_bus_stops_tper.run(action=\"job\", parameters={'bucket': 'datalake'}, local_execution=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "785e801b-bb09-4a16-a8f0-dac15b6667c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_download_train_stops_tper = project.new_function(name=\"download-train-stops-tper\",\n",
    "                                               kind=\"python\",\n",
    "                                               python_version=\"PYTHON3_10\",\n",
    "                                               source={\"source\": \"src/download-open-data.py\", \"handler\": \"download_train_stops_tper\"},\n",
    "                                               requirements= [\"geopandas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "97b6d4f5-d286-415f-9dc8-f99a7438ec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_train_stops_tper = func_download_train_stops_tper.run(action=\"job\", parameters={'bucket': 'datalake'}, local_execution=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd1e6a6-ee79-440f-b9da-8557835e71bf",
   "metadata": {},
   "source": [
    "## Google Drive Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d242a6ee-81c0-477e-84c0-32fc4ba3e73c",
   "metadata": {},
   "source": [
    "### Define and Build Functions: Download Traffic Spire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a07de29-4c0e-42e9-8b60-52ed1e1acea2",
   "metadata": {},
   "source": [
    "#### Create Secret Token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d64c4d-fc95-4633-8a80-2a74c926cdbf",
   "metadata": {},
   "source": [
    "In order to read the files inside Google drive directory, it is required to create secret key,value pair inside to the project. Go to the 'Secret' section of project and create a new secret name 'token' with the value of Google drive token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3ae319c0-e821-421f-9080-50ccc668aff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "project.new_secret(name=\"token\", secret_value=\"YOUR-TOKEN-VALUE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9889b1c-b982-4fa2-b2e7-9b04995b3c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile \"src/download-spire.py\"\n",
    "\n",
    "import os\n",
    "\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# If modifying these scopes, delete the file token.json.\n",
    "SCOPES = [\"https://www.googleapis.com/auth/drive.readonly\"]\n",
    "\n",
    "def getGService(project, token_uri):\n",
    "    creds = None\n",
    "    token = token_uri.read_secret_value()\n",
    "    try:\n",
    "        token_info = json.loads(token)\n",
    "        creds = Credentials.from_authorized_user_info(token_info, SCOPES)\n",
    "        service = build(\"drive\", \"v3\", credentials=creds)\n",
    "    except HttpError as error:\n",
    "        print(f\"An error occurred: {error}\")\n",
    "\n",
    "    return service\n",
    "\n",
    "def upload_file(s3, bucket: str, path: str, local_path: str, item_name: str):\n",
    "    \"\"\"\n",
    "    Uploads specified data items to a shared S3 bucket and folder.\n",
    "    Requires the environment variables for S3 endpoint and credentials (S3_ENDPOINT_URL, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY).\n",
    "    args:\n",
    "        bucket: The name of the bucket\n",
    "        path: The path within the bucket\n",
    "    \"\"\"\n",
    "\n",
    "    name = path + '/' + item_name\n",
    "    s3.upload_file(local_path, bucket, name, ExtraArgs={'ContentType': 'application/octet-stream'})\n",
    "\n",
    "\n",
    "def extract_date_flussi(item_name):\n",
    "    try:\n",
    "        return datetime.datetime.strptime(item_name, 'FLUSSI%Y%m%d.txt')\n",
    "    except Exception as e:\n",
    "        try:\n",
    "            return datetime.datetime.strptime(item_name, 'FLUSS%Y%m%d.txt')\n",
    "        except Exception as e2:\n",
    "            return None\n",
    "\n",
    "def extract_date_accuracy(item_name):\n",
    "    try:\n",
    "        return datetime.datetime.strptime(item_name, 'accur%Y%m%d.txt')\n",
    "    except Exception as e:\n",
    "        try:\n",
    "            return datetime.datetime.strptime(item_name, 'accur%Y%m%d.txt')\n",
    "        except Exception as e2:\n",
    "            return None\n",
    "       \n",
    "def process_file(service, item_id, item_name, date_extractor):\n",
    "    r = service.files().get_media(fileId=item_id)\n",
    "    local_path = 'myfile'\n",
    "    with open(local_path, \"wb\") as fh:\n",
    "        downloader = MediaIoBaseDownload(fh, r)\n",
    "        done = False\n",
    "        while not done:\n",
    "            status, done = downloader.next_chunk()\n",
    "\n",
    "    data = date_extractor(item_name)\n",
    "    if data == None:\n",
    "        print(f\"Error: unknown file : {item_name}\")\n",
    "        return\n",
    "    \n",
    "    f = open(f\"myfile\", \"r\")\n",
    "    sensor = None\n",
    "    entries = []\n",
    "    count = 0\n",
    "    for x in f:\n",
    "        if x.startswith('Section'):\n",
    "            sensor = x.split('Section ')[1].strip()\n",
    "            count = 0\n",
    "        else:\n",
    "            arr = x.split('\\t')\n",
    "            lc = 0\n",
    "            for i in range(len(arr)):\n",
    "                if arr[i].strip() != '':\n",
    "                    d = data.strftime(\"%Y-%m-%d\")\n",
    "                    t = datetime.time(hour = (count + i) // 12, minute = i % 12 * 5).strftime(\"%H:%M\")\n",
    "                    entries.append({\n",
    "                        'sensor_id': sensor,\n",
    "                        'date': d,\n",
    "                        'time': t,\n",
    "                        'start': d + ' ' + t,\n",
    "                        'value': int(int(arr[i]) / 12)\n",
    "                    })\n",
    "                    lc += 1\n",
    "            count += lc\n",
    "\n",
    "    df = pd.DataFrame(entries)\n",
    "    fname = data.strftime(\"%Y-%m\")\n",
    "    if not os.path.exists(f\"data/{fname}.parquet\"):\n",
    "        df.to_parquet(f\"data/{fname}.parquet\")\n",
    "    else:\n",
    "        rdf = pd.read_parquet(f\"data/{fname}.parquet\")\n",
    "        rdf = pd.concat([rdf, df])\n",
    "        rdf.to_parquet(f\"data/{fname}.parquet\")\n",
    "    \n",
    "def process_folder(service, folder, date_extractor):\n",
    "    \"\"\"Downloads recursively all content from a specific year folder on Google Drive.\"\"\"\n",
    "    files = service.files()\n",
    "    request = files.list(q=f\"'{folder['id']}' in parents\", \n",
    "                         supportsAllDrives=True, includeItemsFromAllDrives=True, \n",
    "                         fields=\"nextPageToken, files(id, name, mimeType)\")\n",
    "    print(f\"folder {str(folder['name'])}\")\n",
    "    while request is not None:\n",
    "        results = request.execute()\n",
    "        \n",
    "        items = results.get(\"files\", [])\n",
    "        for item in items:\n",
    "            item_name = item[\"name\"]\n",
    "            item_id = item[\"id\"]\n",
    "            item_type = item[\"mimeType\"]\n",
    "\n",
    "            # If it's a folder, recursively download its content as it is month folder\n",
    "            if item_type == \"application/vnd.google-apps.folder\":\n",
    "                print(f\"Downloading folder {item_name}...\")\n",
    "                process_folder(service, item, date_extractor)\n",
    "            else:\n",
    "                print(f\"Downloading file {item_name}...\")\n",
    "                process_file(service, item_id, item_name, date_extractor)\n",
    "        request = files.list_next(request, results)\n",
    "\n",
    "def process_all(project, token_uri, query: str, s3, bucket: str, destination_path: str, date_extractor):\n",
    "    service = getGService(project, token_uri)\n",
    "    results = (service.files()\n",
    "               .list(q=query, pageSize=1, fields=\"files(id, name, mimeType)\", supportsAllDrives=True, includeItemsFromAllDrives=True)\n",
    "               .execute())\n",
    "    \n",
    "    root_items = results.get(\"files\", [])\n",
    "    for item in root_items:\n",
    "        files = service.files()\n",
    "        request = files.list(q=f\"'{item['id']}' in parents\", \n",
    "                     supportsAllDrives=True, includeItemsFromAllDrives=True, \n",
    "                     fields=\"nextPageToken, files(id, name, mimeType)\")\n",
    "        while request is not None:\n",
    "            results = request.execute()\n",
    "            years = results.get(\"files\", [])\n",
    "            for year in years:\n",
    "                # if year[\"name\"] == \"2024\":\n",
    "                #     continue\n",
    "                    \n",
    "                process_folder(service, year, date_extractor)\n",
    "                rdf = pd.DataFrame()\n",
    "                for i in range(1, 13):\n",
    "                    mf = datetime.date(int(year[\"name\"]), i, 1).strftime(\"%Y-%m\")\n",
    "                    if os.path.exists(f\"data/{mf}.parquet\"):\n",
    "                        rdf = pd.concat([rdf, pd.read_parquet(f\"data/{mf}.parquet\")])\n",
    "                rdf.to_parquet(f\"data/{year['name']}.parquet\")\n",
    "                upload_file(s3, bucket, destination_path + \"/\" + year[\"name\"], f\"data/{year['name']}.parquet\", \"trafic-spire.parquet\")\n",
    "                if year[\"name\"] == datetime.datetime.now().strftime(\"%Y\"):\n",
    "                    upload_file(s3, bucket, destination_path + \"/latest\", f\"data/{year['name']}.parquet\", \"trafic-spire.parquet\")\n",
    "                    \n",
    "            request = files.list_next(request, results)\n",
    "\n",
    "def get_spire(project, bucket):\n",
    "    \n",
    "    base_folder = './data'\n",
    "        \n",
    "    if not os.path.exists(base_folder):\n",
    "        os.makedirs(base_folder)\n",
    "\n",
    "    s3 = boto3.client('s3',\n",
    "                endpoint_url=os.environ.get('S3_ENDPOINT_URL'),\n",
    "                aws_access_key_id=os.environ.get('AWS_ACCESS_KEY_ID'),\n",
    "                aws_secret_access_key=os.environ.get('AWS_SECRET_ACCESS_KEY'))\n",
    "\n",
    "    token_uri = project.get_secret('token')\n",
    "\n",
    "    process_all(project, token_uri, \"mimeType='application/vnd.google-apps.folder' and name='Flussi spire'\", s3, bucket, \"mobility-data/trafic-spire\", extract_date_flussi)\n",
    "\n",
    "\n",
    "def get_spire_accur(project, bucket):\n",
    "    base_folder = './data'\n",
    "        \n",
    "    if not os.path.exists(base_folder):\n",
    "        os.makedirs(base_folder)\n",
    "\n",
    "    s3 = boto3.client('s3',\n",
    "                endpoint_url=os.environ.get('S3_ENDPOINT_URL'),\n",
    "                aws_access_key_id=os.environ.get('AWS_ACCESS_KEY_ID'),\n",
    "                aws_secret_access_key=os.environ.get('AWS_SECRET_ACCESS_KEY'))\n",
    "    \n",
    "    token_uri = project.get_secret('token')\n",
    "\n",
    "    process_all(project, token_uri, \"mimeType='application/vnd.google-apps.folder' and name='Diagnostica'\", s3, bucket, \"mobility-data/trafic-spire-accur\", extract_date_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d469ffdd-7b8c-4075-9b61-45b2b4ad318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_download_traffic_spire = project.new_function(\n",
    "    name=\"download-traffic-spire\",\n",
    "    kind=\"python\",\n",
    "    python_version=\"PYTHON3_10\",\n",
    "    source={\"source\": \"src/download-spire.py\", \"handler\": \"get_spire\"},\n",
    "    requirements=['google-api-python-client', 'google_auth_oauthlib']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e724f5e-85a0-4875-bfd7-0581029b60de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-api-python-client google_auth_oauthlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f773041c-2c2f-4dfa-a8a1-e94a26d7df07",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_traffic_spire = func_download_traffic_spire.run(action=\"job\", parameters={'bucket': 'datalake'}, local_execution=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a97b8c-d6aa-4278-85ea-d71736776c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_download_traffic_spire_accuracy = project.new_function(\n",
    "    name=\"download-traffic-spire-accuracy\",\n",
    "    kind=\"python\",\n",
    "    python_version=\"PYTHON3_10\",\n",
    "    source={\"source\": \"src/download-spire.py\", \"handler\": \"get_spire_accur\"},\n",
    "    requirements=['google-api-python-client', 'google_auth_oauthlib']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a7e71a-1d05-4f1e-b218-27228328dc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_traffic_spire_accuracy = func_download_traffic_spire_accuracy.run(action=\"job\", parameters={'bucket': 'datalake'}, local_execution=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119c50f2-b14e-4ee8-8ac4-6e395a8afd58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
