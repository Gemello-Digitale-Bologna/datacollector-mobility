{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6effd0c6-c127-4499-92aa-963101c4601d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import digitalhub as dh\n",
    "import os\n",
    "PROJECT_NAME = \"mobility-data\"\n",
    "project = dh.get_or_create_project(PROJECT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ba9323-b2bd-4fff-a494-193efd5f3e37",
   "metadata": {},
   "source": [
    "## Open Data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9b7ab47-2d1d-449e-bbf1-43bea0861cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_folder ='src'\n",
    "if not os.path.exists(new_folder):\n",
    "    os.makedirs(new_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e6eb23c-af5c-4704-88b3-afaac357d957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/download-open-data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"src/download-open-data.py\"\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json as js\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import boto3\n",
    "import datetime\n",
    "\n",
    "base_url = \"https://opendata.comune.bologna.it/api/explore/v2.1/catalog/datasets/{name}/exports/geojson\"\n",
    "\n",
    "def download_share_geo(project, bucket, name, artifact_name):\n",
    "    json = requests.get(base_url.format(name = name)).json()  \n",
    "    if not os.path.exists('./data'):\n",
    "        os.makedirs('./data')\n",
    "\n",
    "    path_geojson = './data/'+name+'.geojson'\n",
    "    with open(path_geojson, 'w') as out_file:\n",
    "        out_file.write(js.dumps(json, indent=4))\n",
    "    gdf = gpd.read_file(path_geojson)\n",
    "    \n",
    "    path_parquet = './data/'+name+'.parquet'\n",
    "    gdf.to_parquet(path_parquet)\n",
    "    share_files(project, bucket, path_parquet, artifact_name)  \n",
    "\n",
    "def share_files(project, bucket: str = \"dataspace\", path: str = \"city\", artifactName: str = 'artifact'):\n",
    "    \"\"\"\n",
    "    Uploads specified data items to a shared S3 bucket and folder.\n",
    "    Requires the environment variables for S3 endpoint and credentials (S3_ENDPOINT_URL, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY).\n",
    "    args:\n",
    "        bucket: The name of the bucket\n",
    "        path: The path within the bucket\n",
    "    \"\"\"\n",
    "\n",
    "    s3 = boto3.client('s3',\n",
    "                    endpoint_url=os.environ.get('S3_ENDPOINT_URL'),\n",
    "                    aws_access_key_id=os.environ.get('AWS_ACCESS_KEY_ID'),\n",
    "                    aws_secret_access_key=os.environ.get('AWS_SECRET_ACCESS_KEY'))\n",
    "    \n",
    "    path_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    path_latest = 'latest'\n",
    "    \n",
    "    fname = path.split(\"/\")[-1]\n",
    "    name = fname.split(\".\")[0]\n",
    "\n",
    "    print(bucket)\n",
    "    s3.upload_file(\"./data/\" +fname, bucket, '/' + artifactName + '/' + path_latest + '/' + fname, ExtraArgs={'ContentType': 'application/octet-stream'})\n",
    "    s3.upload_file(\"./data/\" +fname, bucket, '/' + artifactName + '/' + path_date + '/' + fname, ExtraArgs={'ContentType': 'application/octet-stream'})    \n",
    "\n",
    "def download_road_areas(project, bucket):\n",
    "    data = download_share_geo(project, bucket, \"aree-stradali\", \"ctm_road_areas\")\n",
    "\n",
    "def download_curves(project, bucket):\n",
    "    data = download_share_geo(project, bucket, \"carta-tecnica-comunale-curve-livello-10-metri\", \"ctm_level_curves_10m\")\n",
    "\n",
    "def download_sidewalks(project, bucket):\n",
    "    data = download_share_geo(project, bucket, \"carta-tecnica-comunale-marciapiedi\", \"ctm_level_sidewalks\")\n",
    "\n",
    "def download_road_edges(project, bucket):\n",
    "    data = download_share_geo(project, bucket, \"rifter_arcstra_li\", \"rifter_edges\")\n",
    "\n",
    "def download_road_nodes(project, bucket):\n",
    "    data = download_share_geo(project, bucket, \"rifter_nodi_pt\", \"rifter_nodes\")\n",
    "\n",
    "def download_city_30(project, bucket):\n",
    "    data = download_share_geo(project, bucket, \"velocita-citta-30\", \"city_30\")\n",
    "\n",
    "def download_charging_stations(project, bucket):\n",
    "    data = download_share_geo(project, bucket, \"colonnine-elettriche\", \"charging_stations\")\n",
    "\n",
    "def download_bike_path(project, bucket):\n",
    "    data = download_share_geo(project, bucket, \"piste-ciclopedonali\", \"bike_path\")\n",
    "\n",
    "def download_incidents(project, bucket):\n",
    "    data = download_share_geo(project, bucket, \"incidenti_new\", \"car_incidents\")\n",
    "\n",
    "def download_bike_parking_places(project, bucket):\n",
    "    data = download_share_geo(project, bucket, \"rastrelliere-per-biciclette\", \"bike_parking_places\")\n",
    "\n",
    "def download_car_parkings(project, bucket):\n",
    "    data = download_share_geo(project, bucket, \"parcheggi\", \"car_parkings\")\n",
    "\n",
    "def download_bus_stops_tper(project, bucket):\n",
    "    data = download_share_geo(project, bucket, \"tper-fermate-autobus\", \"tper_bus_stops\")\n",
    "\n",
    "def download_train_stops_tper(project, bucket):\n",
    "    data = download_share_geo(project, bucket, \"stazioniferroviarie_20210401\", \"tper_train_stops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fb9814c-1e96-4d64-a057-986f8424eb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_download_road_areas = project.new_function(name=\"download-road-areas\",\n",
    "                                               kind=\"python\",\n",
    "                                               python_version=\"PYTHON3_10\",\n",
    "                                               source={\"source\": \"src/download-open-data.py\", \"handler\": \"download_road_areas\"},\n",
    "                                               requirements= [\"geopandas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90c46404-5465-4a74-8d1d-a4c96acd6a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_road_areas = func_download_road_areas.run(action=\"job\", parameters={'bucket': 'datalake'}, local_execution=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5135621a-e01e-4c68-87fc-334dd3081ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_download_road_edges = project.new_function(name=\"download-road-edges\",\n",
    "                                               kind=\"python\",\n",
    "                                               python_version=\"PYTHON3_10\",\n",
    "                                               source={\"source\": \"src/download-open-data.py\", \"handler\": \"download_road_edges\"},\n",
    "                                               requirements= [\"geopandas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f50cd449-9866-44c5-a492-6a019de5a2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_road_edges = func_download_road_edges.run(action=\"job\", parameters={'bucket': 'datalake'}, local_execution=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ee217d7-c86d-4acb-97c9-672a2e10e954",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_download_road_nodes = project.new_function(name=\"download-road-nodes\",\n",
    "                                               kind=\"python\",\n",
    "                                               python_version=\"PYTHON3_10\",\n",
    "                                               source={\"source\": \"src/download-open-data.py\", \"handler\": \"download_road_nodes\"},\n",
    "                                               requirements= [\"geopandas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78ecb3d0-0598-4e46-8d8a-5b89a74b097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_road_nodes = func_download_road_nodes.run(action=\"job\", parameters={'bucket': 'datalake'}, local_execution=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9630c407-5f8f-4edd-bd78-2ea4db256bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_download_curves = project.new_function(name=\"download-curves\",\n",
    "                                               kind=\"python\",\n",
    "                                               python_version=\"PYTHON3_10\",\n",
    "                                               source={\"source\": \"src/download-open-data.py\", \"handler\": \"download_curves\"},\n",
    "                                               requirements= [\"geopandas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9223a11-f72b-4a11-b6c2-96cb47dabfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_curves = func_download_curves.run(action=\"job\", parameters={'bucket': 'datalake'}, local_execution=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f296319d-2434-4ed4-8bfb-16cd48dfce6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_download_sidewalks = project.new_function(name=\"download-sidewalks\",\n",
    "                                               kind=\"python\",\n",
    "                                               python_version=\"PYTHON3_10\",\n",
    "                                               source={\"source\": \"src/download-open-data.py\", \"handler\": \"download_sidewalks\"},\n",
    "                                               requirements= [\"geopandas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acbfb792-bc5f-4338-849e-8ea7dd87d038",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_sidewalks = func_download_sidewalks.run(action=\"job\", parameters={'bucket': 'datalake'}, local_execution=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "295ac699-db5e-428e-9bb5-a51cea0e4c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_download_city30 = project.new_function(name=\"download-city30\",\n",
    "                                               kind=\"python\",\n",
    "                                               python_version=\"PYTHON3_10\",\n",
    "                                               source={\"source\": \"src/download-open-data.py\", \"handler\": \"download_city_30\"},\n",
    "                                               requirements= [\"geopandas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6f61d7b-c8fb-4e9c-8601-34deb1806908",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_city30 = func_download_city30.run(action=\"job\", parameters={'bucket': 'datalake'}, local_execution=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ed32be2-1536-439b-bab0-711d473ba0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_download_charging_stations = project.new_function(name=\"download-charging-stations\",\n",
    "                                               kind=\"python\",\n",
    "                                               python_version=\"PYTHON3_10\",\n",
    "                                               source={\"source\": \"src/download-open-data.py\", \"handler\": \"download_charging_stations\"},\n",
    "                                               requirements= [\"geopandas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f867ffc-145c-40dd-b6bf-34dc8981a63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_charging_stations = func_download_charging_stations.run(action=\"job\", parameters={'bucket': 'datalake'}, local_execution=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3558d2d-19fa-4da2-9c7f-2794722b5c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_download_bike_path = project.new_function(name=\"download-bike-path\",\n",
    "                                               kind=\"python\",\n",
    "                                               python_version=\"PYTHON3_10\",\n",
    "                                               source={\"source\": \"src/download-open-data.py\", \"handler\": \"download_bike_path\"},\n",
    "                                               requirements= [\"geopandas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af9b4414-8409-4fe8-8c1a-3793aa05e203",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_bike_path = func_download_bike_path.run(action=\"job\", parameters={'bucket': 'datalake'}, local_execution=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74bf1e38-b47c-42f2-9793-8316ad978fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_download_incidents = project.new_function(name=\"download-incidents\",\n",
    "                                               kind=\"python\",\n",
    "                                               python_version=\"PYTHON3_10\",\n",
    "                                               source={\"source\": \"src/download-open-data.py\", \"handler\": \"download_incidents\"},\n",
    "                                               requirements= [\"geopandas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ae1fbc0-6ee7-42d7-85db-329a3cff6921",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_incidents = func_download_incidents.run(action=\"job\", parameters={'bucket': 'datalake'}, local_execution=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9254682b-53c0-4b6b-bec4-0824c3a6bdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_download_bike_parking_places = project.new_function(name=\"download-bike-parking-places\",\n",
    "                                               kind=\"python\",\n",
    "                                               python_version=\"PYTHON3_10\",\n",
    "                                               source={\"source\": \"src/download-open-data.py\", \"handler\": \"download_bike_parking_places\"},\n",
    "                                               requirements= [\"geopandas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0fac73f-ff58-4cc1-b59c-9913390c09d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_bike_parking_places = func_download_bike_parking_places.run(action=\"job\", parameters={'bucket': 'datalake'}, local_execution=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7267f03c-e386-42f4-ba73-3522c3a301df",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_download_car_parkings = project.new_function(name=\"download-bike-parking-places\",\n",
    "                                               kind=\"python\",\n",
    "                                               python_version=\"PYTHON3_10\",\n",
    "                                               source={\"source\": \"src/download-open-data.py\", \"handler\": \"download_car_parkings\"},\n",
    "                                               requirements= [\"geopandas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8015c2c-8d3e-4cec-926e-b9b5ef4d9d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_car_parkings = func_download_car_parkings.run(action=\"job\", parameters={'bucket': 'datalake'}, local_execution=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "21274d7f-9128-4def-95d8-6ce39161c110",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_download_bus_stops_tper = project.new_function(name=\"download-bus-stops-tper\",\n",
    "                                               kind=\"python\",\n",
    "                                               python_version=\"PYTHON3_10\",\n",
    "                                               source={\"source\": \"src/download-open-data.py\", \"handler\": \"download_bus_stops_tper\"},\n",
    "                                               requirements= [\"geopandas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f3904b3-da9e-4a99-8708-f9fab253a406",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_bus_stops_tper = func_download_bus_stops_tper.run(action=\"job\", parameters={'bucket': 'datalake'}, local_execution=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "785e801b-bb09-4a16-a8f0-dac15b6667c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_download_train_stops_tper = project.new_function(name=\"download-train-stops-tper\",\n",
    "                                               kind=\"python\",\n",
    "                                               python_version=\"PYTHON3_10\",\n",
    "                                               source={\"source\": \"src/download-open-data.py\", \"handler\": \"download_train_stops_tper\"},\n",
    "                                               requirements= [\"geopandas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "97b6d4f5-d286-415f-9dc8-f99a7438ec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_train_stops_tper = func_download_train_stops_tper.run(action=\"job\", parameters={'bucket': 'datalake'}, local_execution=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd1e6a6-ee79-440f-b9da-8557835e71bf",
   "metadata": {},
   "source": [
    "## Google Drive Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46fea32-0dba-44c8-b873-59e12de2ec7a",
   "metadata": {},
   "source": [
    "Upload the token file as aritifact in the project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d242a6ee-81c0-477e-84c0-32fc4ba3e73c",
   "metadata": {},
   "source": [
    "### Define and Build Functions: Download Traffic Spire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f33a5a9-667e-4e07-8900-bd1bf834ea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_uri = project.get_artifact('token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c9889b1c-b982-4fa2-b2e7-9b04995b3c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/download-spire.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"src/download-spire.py\"\n",
    "\n",
    "import os\n",
    "\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# If modifying these scopes, delete the file token.json.\n",
    "SCOPES = [\"https://www.googleapis.com/auth/drive.readonly\"]\n",
    "\n",
    "def getGService(project, token_uri):\n",
    "    creds = None\n",
    "    token = token_uri.as_file()\n",
    "    try:\n",
    "        token_info = json.load(open(token))\n",
    "        creds = Credentials.from_authorized_user_info(token_info, SCOPES)\n",
    "        service = build(\"drive\", \"v3\", credentials=creds)\n",
    "    except HttpError as error:\n",
    "        print(f\"An error occurred: {error}\")\n",
    "\n",
    "    return service\n",
    "\n",
    "def upload_file(s3, bucket: str, path: str, local_path: str, item_name: str):\n",
    "    \"\"\"\n",
    "    Uploads specified data items to a shared S3 bucket and folder.\n",
    "    Requires the environment variables for S3 endpoint and credentials (S3_ENDPOINT_URL, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY).\n",
    "    args:\n",
    "        bucket: The name of the bucket\n",
    "        path: The path within the bucket\n",
    "    \"\"\"\n",
    "\n",
    "    name = path + '/' + item_name\n",
    "    s3.upload_file(local_path, bucket, name, ExtraArgs={'ContentType': 'application/octet-stream'})\n",
    "\n",
    "\n",
    "def extract_date_flussi(item_name):\n",
    "    try:\n",
    "        return datetime.datetime.strptime(item_name, 'FLUSSI%Y%m%d.txt')\n",
    "    except Exception as e:\n",
    "        try:\n",
    "            return datetime.datetime.strptime(item_name, 'FLUSS%Y%m%d.txt')\n",
    "        except Exception as e2:\n",
    "            return None\n",
    "\n",
    "def extract_date_accuracy(item_name):\n",
    "    try:\n",
    "        return datetime.datetime.strptime(item_name, 'accur%Y%m%d.txt')\n",
    "    except Exception as e:\n",
    "        try:\n",
    "            return datetime.datetime.strptime(item_name, 'accur%Y%m%d.txt')\n",
    "        except Exception as e2:\n",
    "            return None\n",
    "       \n",
    "def process_file(service, item_id, item_name, date_extractor):\n",
    "    r = service.files().get_media(fileId=item_id)\n",
    "    local_path = 'myfile'\n",
    "    with open(local_path, \"wb\") as fh:\n",
    "        downloader = MediaIoBaseDownload(fh, r)\n",
    "        done = False\n",
    "        while not done:\n",
    "            status, done = downloader.next_chunk()\n",
    "\n",
    "    data = date_extractor(item_name)\n",
    "    if data == None:\n",
    "        print(f\"Error: unknown file : {item_name}\")\n",
    "        return\n",
    "    \n",
    "    f = open(f\"myfile\", \"r\")\n",
    "    sensor = None\n",
    "    entries = []\n",
    "    count = 0\n",
    "    for x in f:\n",
    "        if x.startswith('Section'):\n",
    "            sensor = x.split('Section ')[1].strip()\n",
    "            count = 0\n",
    "        else:\n",
    "            arr = x.split('\\t')\n",
    "            lc = 0\n",
    "            for i in range(len(arr)):\n",
    "                if arr[i].strip() != '':\n",
    "                    d = data.strftime(\"%Y-%m-%d\")\n",
    "                    t = datetime.time(hour = (count + i) // 12, minute = i % 12 * 5).strftime(\"%H:%M\")\n",
    "                    entries.append({\n",
    "                        'sensor_id': sensor,\n",
    "                        'date': d,\n",
    "                        'time': t,\n",
    "                        'start': d + ' ' + t,\n",
    "                        'value': int(int(arr[i]) / 12)\n",
    "                    })\n",
    "                    lc += 1\n",
    "            count += lc\n",
    "\n",
    "    df = pd.DataFrame(entries)\n",
    "    fname = data.strftime(\"%Y-%m\")\n",
    "    if not os.path.exists(f\"data/{fname}.parquet\"):\n",
    "        df.to_parquet(f\"data/{fname}.parquet\")\n",
    "    else:\n",
    "        rdf = pd.read_parquet(f\"data/{fname}.parquet\")\n",
    "        rdf = pd.concat([rdf, df])\n",
    "        rdf.to_parquet(f\"data/{fname}.parquet\")\n",
    "    \n",
    "def process_folder(service, folder, date_extractor):\n",
    "    \"\"\"Downloads recursively all content from a specific year folder on Google Drive.\"\"\"\n",
    "    files = service.files()\n",
    "    request = files.list(q=f\"'{folder['id']}' in parents\", \n",
    "                         supportsAllDrives=True, includeItemsFromAllDrives=True, \n",
    "                         fields=\"nextPageToken, files(id, name, mimeType)\")\n",
    "    print(f\"folder {str(folder['name'])}\")\n",
    "    while request is not None:\n",
    "        results = request.execute()\n",
    "        \n",
    "        items = results.get(\"files\", [])\n",
    "        for item in items:\n",
    "            item_name = item[\"name\"]\n",
    "            item_id = item[\"id\"]\n",
    "            item_type = item[\"mimeType\"]\n",
    "\n",
    "            # If it's a folder, recursively download its content as it is month folder\n",
    "            if item_type == \"application/vnd.google-apps.folder\":\n",
    "                print(f\"Downloading folder {item_name}...\")\n",
    "                process_folder(service, item, date_extractor)\n",
    "            else:\n",
    "                print(f\"Downloading file {item_name}...\")\n",
    "                process_file(service, item_id, item_name, date_extractor)\n",
    "        request = files.list_next(request, results)\n",
    "\n",
    "def process_all(project, token_uri, query: str, s3, bucket: str, destination_path: str, date_extractor):\n",
    "    service = getGService(project, token_uri)\n",
    "    results = (service.files()\n",
    "               .list(q=query, pageSize=1, fields=\"files(id, name, mimeType)\", supportsAllDrives=True, includeItemsFromAllDrives=True)\n",
    "               .execute())\n",
    "    \n",
    "    root_items = results.get(\"files\", [])\n",
    "    for item in root_items:\n",
    "        files = service.files()\n",
    "        request = files.list(q=f\"'{item['id']}' in parents\", \n",
    "                     supportsAllDrives=True, includeItemsFromAllDrives=True, \n",
    "                     fields=\"nextPageToken, files(id, name, mimeType)\")\n",
    "        while request is not None:\n",
    "            results = request.execute()\n",
    "            years = results.get(\"files\", [])\n",
    "            for year in years:\n",
    "                # if year[\"name\"] == \"2024\":\n",
    "                #     continue\n",
    "                    \n",
    "                process_folder(service, year, date_extractor)\n",
    "                rdf = pd.DataFrame()\n",
    "                for i in range(1, 13):\n",
    "                    mf = datetime.date(int(year[\"name\"]), i, 1).strftime(\"%Y-%m\")\n",
    "                    if os.path.exists(f\"data/{mf}.parquet\"):\n",
    "                        rdf = pd.concat([rdf, pd.read_parquet(f\"data/{mf}.parquet\")])\n",
    "                rdf.to_parquet(f\"data/{year['name']}.parquet\")\n",
    "                upload_file(s3, bucket, destination_path + \"/\" + year[\"name\"], f\"data/{year['name']}.parquet\", \"trafic-spire.parquet\")\n",
    "                if year[\"name\"] == datetime.datetime.now().strftime(\"%Y\"):\n",
    "                    upload_file(s3, bucket, destination_path + \"/latest\", f\"data/{year['name']}.parquet\", \"trafic-spire.parquet\")\n",
    "                    \n",
    "            request = files.list_next(request, results)\n",
    "\n",
    "def get_spire(project, token_uri, bucket):\n",
    "    \n",
    "    base_folder = './data'\n",
    "        \n",
    "    if not os.path.exists(base_folder):\n",
    "        os.makedirs(base_folder)\n",
    "\n",
    "    s3 = boto3.client('s3',\n",
    "                endpoint_url=os.environ.get('S3_ENDPOINT_URL'),\n",
    "                aws_access_key_id=os.environ.get('AWS_ACCESS_KEY_ID'),\n",
    "                aws_secret_access_key=os.environ.get('AWS_SECRET_ACCESS_KEY'))\n",
    "\n",
    "\n",
    "    process_all(project, token_uri, \"mimeType='application/vnd.google-apps.folder' and name='Flussi spire'\", s3, bucket, \"mobility-data/trafic-spire\", extract_date_flussi)\n",
    "\n",
    "\n",
    "def get_spire_accur(project, token_uri, bucket):\n",
    "    base_folder = './data'\n",
    "        \n",
    "    if not os.path.exists(base_folder):\n",
    "        os.makedirs(base_folder)\n",
    "\n",
    "    s3 = boto3.client('s3',\n",
    "                endpoint_url=os.environ.get('S3_ENDPOINT_URL'),\n",
    "                aws_access_key_id=os.environ.get('AWS_ACCESS_KEY_ID'),\n",
    "                aws_secret_access_key=os.environ.get('AWS_SECRET_ACCESS_KEY'))\n",
    "\n",
    "\n",
    "    process_all(project, token_uri, \"mimeType='application/vnd.google-apps.folder' and name='Diagnostica'\", s3, bucket, \"mobility-data/trafic-spire-accur\", extract_date_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d469ffdd-7b8c-4075-9b61-45b2b4ad318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_download_traffic_spire = project.new_function(\n",
    "    name=\"download-traffic-spire\",\n",
    "    kind=\"python\",\n",
    "    python_version=\"PYTHON3_10\",\n",
    "    source={\"source\": \"src/download-spire.py\", \"handler\": \"get_spire\"},\n",
    "    requirements=['google-api-python-client', 'google_auth_oauthlib']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5e724f5e-85a0-4875-bfd7-0581029b60de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f773041c-2c2f-4dfa-a8a1-e94a26d7df07",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_traffic_spire = func_download_traffic_spire.run(action=\"job\", inputs={'token_uri': token_uri.key}, parameters={'bucket': 'datalake'}, local_execution=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f3a97b8c-d6aa-4278-85ea-d71736776c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_download_traffic_spire_accuracy = project.new_function(\n",
    "    name=\"download-traffic-spire-accuracy\",\n",
    "    kind=\"python\",\n",
    "    python_version=\"PYTHON3_10\",\n",
    "    source={\"source\": \"src/download-spire.py\", \"handler\": \"get_spire_accur\"},\n",
    "    requirements=['google-api-python-client', 'google_auth_oauthlib']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "23a7e71a-1d05-4f1e-b218-27228328dc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_download_traffic_spire_accuracy = func_download_traffic_spire_accuracy.run(action=\"job\", inputs={'token_uri': token_uri.key}, parameters={'bucket': 'datalake'}, local_execution=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
